import streamlit as st
import pandas as pd
from google import genai
from google.genai.errors import APIError
# ƒê√É S·ª¨A L·ªñI: Lo·∫°i b·ªè import GenerationConfig v√† SystemInstruction ƒë·ªÉ tr√°nh l·ªói Pydantic
# T∆∞∆°ng th√≠ch cao nh·∫•t: System Instruction ƒë∆∞·ª£c truy·ªÅn b·∫±ng c√°ch gh√©p v√†o User Prompt

# --- Kh·ªüi t·∫°o State cho Chatbot v√† D·ªØ li·ªáu ---
# L∆∞u tr·ªØ l·ªãch s·ª≠ chat
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Xin ch√†o! H√£y t·∫£i l√™n B√°o c√°o T√†i ch√≠nh c·ªßa b·∫°n ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch v√† tr√≤ chuy·ªán."}]
# L∆∞u tr·ªØ d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω d∆∞·ªõi d·∫°ng Markdown ƒë·ªÉ l√†m b·ªëi c·∫£nh (context) cho AI
if "data_for_chat" not in st.session_state:
    st.session_state.data_for_chat = None

# --- C·∫•u h√¨nh Trang Streamlit ---
st.set_page_config(
    page_title="App Ph√¢n T√≠ch B√°o C√°o T√†i Ch√≠nh",
    layout="wide"
)

st.title("·ª®ng d·ª•ng Ph√¢n T√≠ch B√°o c√°o T√†i ch√≠nh üìä")

# --- H√†m t√≠nh to√°n ch√≠nh (S·ª≠ d·ª•ng Caching ƒë·ªÉ T·ªëi ∆∞u hi·ªáu su·∫•t) ---
@st.cache_data
def process_financial_data(df):
    """Th·ª±c hi·ªán c√°c ph√©p t√≠nh TƒÉng tr∆∞·ªüng, So s√°nh Tuy·ªát ƒë·ªëi v√† T·ª∑ tr·ªçng cho 3 nƒÉm (NƒÉm 1, NƒÉm 2, NƒÉm 3)."""
    
    # ƒê·∫£m b·∫£o c√°c gi√° tr·ªã l√† s·ªë ƒë·ªÉ t√≠nh to√°n
    numeric_cols = ['NƒÉm 1', 'NƒÉm 2', 'NƒÉm 3']
    for col in numeric_cols:
        # Chuy·ªÉn ƒë·ªïi sang d·∫°ng s·ªë, thay th·∫ø l·ªói b·∫±ng 0
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    
    # 1. So s√°nh Y2 vs Y1 (31/12/2024 vs 31/12/2023)
    df['Delta (Y2 vs Y1)'] = df['NƒÉm 2'] - df['NƒÉm 1']
    # D√πng .replace(0, 1e-9) cho Series Pandas ƒë·ªÉ tr√°nh l·ªói chia cho 0
    df['Growth (Y2 vs Y1)'] = (
        df['Delta (Y2 vs Y1)'] / df['NƒÉm 1'].replace(0, 1e-9)
    ) * 100

    # 2. So s√°nh Y3 vs Y2 (30/06/2025 vs 31/12/2024)
    df['Delta (Y3 vs Y2)'] = df['NƒÉm 3'] - df['NƒÉm 2']
    # D√πng .replace(0, 1e-9) cho Series Pandas ƒë·ªÉ tr√°nh l·ªói chia cho 0
    df['Growth (Y3 vs Y2)'] = (
        df['Delta (Y3 vs Y2)'] / df['NƒÉm 2'].replace(0, 1e-9)
    ) * 100

    # 3. T√≠nh T·ª∑ tr·ªçng theo T·ªïng T√†i s·∫£n
    # L·ªçc ch·ªâ ti√™u "T·ªîNG C·ªòNG T√ÄI S·∫¢N" ho·∫∑c "T·ªîNG C·ªòNG"
    tong_tai_san_row = df[df['Ch·ªâ ti√™u'].str.contains('T·ªîNG C·ªòNG T√ÄI S·∫¢N|T·ªîNG C·ªòNG', case=False, na=False)]
    
    if tong_tai_san_row.empty:
        raise ValueError("Kh√¥ng t√¨m th·∫•y ch·ªâ ti√™u 'T·ªîNG C·ªòNG T√ÄI S·∫¢N' ho·∫∑c 'T·ªîNG C·ªòNG' ƒë·ªÉ t√≠nh t·ª∑ tr·ªçng. Vui l√≤ng ki·ªÉm tra t√™n ch·ªâ ti√™u trong file.")

    tong_tai_san_N1 = tong_tai_san_row['NƒÉm 1'].iloc[0]
    tong_tai_san_N2 = tong_tai_san_row['NƒÉm 2'].iloc[0]
    tong_tai_san_N3 = tong_tai_san_row['NƒÉm 3'].iloc[0]

    # X·ª≠ l√Ω m·∫´u s·ªë b·∫±ng 0
    divisor_N1 = tong_tai_san_N1 if tong_tai_san_N1 != 0 else 1e-9
    divisor_N2 = tong_tai_san_N2 if tong_tai_san_N2 != 0 else 1e-9
    divisor_N3 = tong_tai_san_N3 if tong_tai_san_N3 != 0 else 1e-9

    # T√≠nh t·ª∑ tr·ªçng
    df['T·ª∑ tr·ªçng NƒÉm 1 (%)'] = (df['NƒÉm 1'] / divisor_N1) * 100
    df['T·ª∑ tr·ªçng NƒÉm 2 (%)'] = (df['NƒÉm 2'] / divisor_N2) * 100
    df['T·ª∑ tr·ªçng NƒÉm 3 (%)'] = (df['NƒÉm 3'] / divisor_N3) * 100
    
    return df

# --- H√†m g·ªçi API Gemini cho Ph√¢n t√≠ch B√°o c√°o (Single-shot analysis) ---
def get_ai_analysis(data_for_ai, api_key):
    """G·ª≠i d·ªØ li·ªáu ph√¢n t√≠ch ƒë·∫øn Gemini API v√† nh·∫≠n nh·∫≠n x√©t."""
    try:
        client = genai.Client(api_key=api_key)
        model_name = 'gemini-2.5-flash' 
        
        system_instruction_text = (
            "B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch t√†i ch√≠nh chuy√™n nghi·ªáp. "
            "D·ª±a tr√™n d·ªØ li·ªáu ƒë√£ cung c·∫•p, h√£y ƒë∆∞a ra m·ªôt nh·∫≠n x√©t kh√°ch quan, ng·∫Øn g·ªçn (kho·∫£ng 3-4 ƒëo·∫°n) v·ªÅ t√¨nh h√¨nh t√†i ch√≠nh c·ªßa doanh nghi·ªáp. "
            "ƒê√°nh gi√° t·∫≠p trung v√†o t·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng qua c√°c chu k·ª≥, thay ƒë·ªïi c∆° c·∫•u t√†i s·∫£n v√† kh·∫£ nƒÉng thanh to√°n hi·ªán h√†nh trong 3 nƒÉm/k·ª≥."
        )
        
        # S·ª¨A L·ªñI: Gh√©p System Instruction v√†o ƒë·∫ßu Prompt ƒë·ªÉ t∆∞∆°ng th√≠ch API
        user_prompt = f"""
        {system_instruction_text}
        
        D·ªØ li·ªáu th√¥ v√† ch·ªâ s·ªë:
        {data_for_ai}
        """

        # Truy·ªÅn prompt duy nh·∫•t
        response = client.models.generate_content(
            model=model_name,
            contents=user_prompt 
        )
        return response.text

    except APIError as e:
        return f"L·ªói g·ªçi Gemini API: Vui l√≤ng ki·ªÉm tra Kh√≥a API ho·∫∑c gi·ªõi h·∫°n s·ª≠ d·ª•ng. Chi ti·∫øt l·ªói: {e}"
    except KeyError:
        return "L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API 'GEMINI_API_KEY'. Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh Secrets tr√™n Streamlit Cloud."
    except Exception as e:
        return f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"


# --- H√†m g·ªçi API Gemini cho CHAT t∆∞∆°ng t√°c (c√≥ qu·∫£n l√Ω l·ªãch s·ª≠) ---
def get_chat_response(prompt, chat_history_st, context_data, api_key):
    try:
        client = genai.Client(api_key=api_key)
        model_name = 'gemini-2.5-flash'
        
        # 1. ƒê·ªãnh nghƒ©a System Instruction
        system_instruction_text = (
            "B·∫°n l√† m·ªôt tr·ª£ l√Ω ph√¢n t√≠ch t√†i ch√≠nh th√¥ng minh (Financial Analyst Assistant). "
            "B·∫°n ph·∫£i tr·∫£ l·ªùi c√°c c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng d·ª±a tr√™n d·ªØ li·ªáu t√†i ch√≠nh ƒë√£ x·ª≠ l√Ω sau. "
            "D·ªØ li·ªáu n√†y bao g·ªìm t·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng, so s√°nh tuy·ªát ƒë·ªëi/t∆∞∆°ng ƒë·ªëi v√† t·ª∑ tr·ªçng trong 3 k·ª≥ B√°o c√°o t√†i ch√≠nh, c√πng v·ªõi 3 ch·ªâ s·ªë thanh to√°n hi·ªán h√†nh. "
            "N·∫øu ng∆∞·ªùi d√πng h·ªèi m·ªôt c√¢u kh√¥ng li√™n quan ƒë·∫øn d·ªØ li·ªáu t√†i ch√≠nh ho·∫∑c ph√¢n t√≠ch, h√£y l·ªãch s·ª± t·ª´ ch·ªëi tr·∫£ l·ªùi. "
            "D·ªØ li·ªáu t√†i ch√≠nh ƒë√£ x·ª≠ l√Ω (ƒë∆∞·ª£c tr√¨nh b√†y d∆∞·ªõi d·∫°ng Markdown ƒë·ªÉ b·∫°n d·ªÖ hi·ªÉu): \n\n" + context_data
        )
        
        # 2. Chuy·ªÉn ƒë·ªïi l·ªãch s·ª≠ Streamlit sang ƒë·ªãnh d·∫°ng Gemini
        gemini_history = []
        # B·∫Øt ƒë·∫ßu t·ª´ tin nh·∫Øn th·ª© hai trong l·ªãch s·ª≠ ST (b·ªè qua tin nh·∫Øn ch√†o m·ª´ng ƒë·∫ßu ti√™n)
        for msg in chat_history_st[1:]: 
            # ƒê·∫£m b·∫£o ch·ªâ c√≥ role 'user' v√† 'model' ƒë∆∞·ª£c s·ª≠ d·ª•ng
            role = "user" if msg["role"] == "user" else "model"
            gemini_history.append({"role": role, "parts": [{"text": msg["content"]}]})
        
        # 3. Gh√©p System Instruction v√† Prompt m·ªõi nh·∫•t v√†o Content cu·ªëi c√πng
        last_user_prompt = prompt
        
        # T·∫°o prompt cu·ªëi c√πng b·∫±ng c√°ch gh√©p System Instruction, Context Data v√† Prompt ng∆∞·ªùi d√πng
        final_prompt = f"""
        {system_instruction_text}
        
        ---
        
        C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {last_user_prompt}
        """

        # Th√™m prompt cu·ªëi c√πng (final_prompt) v√†o cu·ªëi l·ªãch s·ª≠
        full_contents = gemini_history
        full_contents.append({"role": "user", "parts": [{"text": final_prompt}]})


        # 4. G·ªçi API
        response = client.models.generate_content(
            model=model_name,
            contents=full_contents 
        )
        return response.text

    except APIError as e:
        return f"L·ªói g·ªçi Gemini API: Vui l√≤ng ki·ªÉm tra Kh√≥a API ho·∫∑c gi·ªõi h·∫°n s·ª≠ d·ª•ng. Chi ti·∫øt l·ªói: {e}"
    except Exception as e:
        return f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"


# --- Ch·ª©c nƒÉng 1: T·∫£i File ---
uploaded_file = st.file_uploader(
    "1. T·∫£i file Excel/CSV B√°o c√°o T√†i ch√≠nh (KHO·∫¢N M·ª§C | YYYY-MM-DD | YYYY-MM-DD | YYYY-MM-DD)",
    type=['xlsx', 'xls', 'csv']
)

if uploaded_file is not None:
    try:
        # X·ª≠ l√Ω file d·ª±a tr√™n ƒë·ªãnh d·∫°ng
        # D√πng header=0 ƒë·ªÉ l·∫•y t√™n c·ªôt l√† ng√†y th√°ng
        if uploaded_file.name.endswith(('.xlsx', '.xls')):
            df_raw = pd.read_excel(uploaded_file, header=0)
        elif uploaded_file.name.endswith('.csv'):
            df_raw = pd.read_csv(uploaded_file, header=0)
        else:
            raise Exception("ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£.")

        # --- TI·ªÄN X·ª¨ L√ù (PRE-PROCESSING) D·ªÆ LI·ªÜU ƒê·ªÇ PH√ô H·ª¢P V·ªöI LOGIC C≈® ---
        
        # 1. ƒê·∫∑t t√™n c·ªôt ƒë·∫ßu ti√™n l√† 'Ch·ªâ ti√™u' (D·ª±a tr√™n snippet 'KHO·∫¢N M·ª§C')
        df_raw = df_raw.rename(columns={df_raw.columns[0]: 'Ch·ªâ ti√™u'})
        
        # 2. X√°c ƒë·ªãnh c·ªôt nƒÉm g·∫ßn nh·∫•t ('NƒÉm 3'), 'NƒÉm 2', 'NƒÉm 1'
        
        # T√åM KI·∫æM C·ªòT NG√ÄY TH√ÅNG LINH HO·∫†T
        value_cols_unique = {} # D√πng dictionary ƒë·ªÉ ƒë·∫£m b·∫£o key (gi√° tr·ªã ng√†y) l√† duy nh·∫•t
        for col in df_raw.columns:
            col_str = str(col)
            
            # H√†m ph·ª• ƒë·ªÉ chu·∫©n h√≥a t√™n c·ªôt (lo·∫°i b·ªè gi·ªù v√† ƒë·ªãnh d·∫°ng YYYY-MM-DD)
            def normalize_date_col(name):
                # Lo·∫°i b·ªè ph·∫ßn gi·ªù n·∫øu c√≥
                if ' ' in name:
                    name = name.split(' ')[0]
                return name
            
            normalized_name = normalize_date_col(col_str)
            
            # Ki·ªÉm tra n·∫øu t√™n chu·∫©n h√≥a l√† ng√†y th√°ng (v√≠ d·ª•: '2023-12-31')
            if len(normalized_name) >= 10 and normalized_name[4] == '-' and normalized_name[7] == '-' and normalized_name[:4].isdigit():
                 # N·∫øu t√™n ng√†y th√°ng (normalized_name) ch∆∞a c√≥ trong dict, th√™m c·ªôt g·ªëc (col) v√†o
                 if normalized_name not in value_cols_unique:
                    value_cols_unique[normalized_name] = col
            # Ho·∫∑c t√¨m c√°c c·ªôt c√≥ t√™n l√† nƒÉm ƒë∆°n thu·∫ßn (VD: 2023)
            elif normalized_name.isdigit() and len(normalized_name) == 4 and normalized_name.startswith('20'):
                 if normalized_name not in value_cols_unique:
                    value_cols_unique[normalized_name] = col

        # L·∫•y danh s√°ch c√°c c·ªôt g·ªëc kh√¥ng tr√πng l·∫∑p (Value c·ªßa dictionary)
        value_cols = list(value_cols_unique.values())
        
        if len(value_cols) < 3: # Y√™u c·∫ßu 3 nƒÉm ƒë·ªÉ t√≠nh to√°n 2 chu k·ª≥
            st.warning(f"Ch·ªâ t√¨m th·∫•y {len(value_cols)} c·ªôt nƒÉm. ·ª®ng d·ª•ng c·∫ßn √≠t nh·∫•t 3 nƒÉm/k·ª≥ ƒë·ªÉ so s√°nh.")
            st.stop()
            
        # Ch·ªçn 3 c·ªôt nƒÉm g·∫ßn nh·∫•t (S·∫Øp x·∫øp theo t√™n c·ªôt/ng√†y th√°ng, m·ªõi nh·∫•t (Y3) l√™n ƒë·∫ßu)
        value_cols.sort(key=lambda x: str(x), reverse=True)
        
        col_nam_3 = value_cols[0] # Newest (NƒÉm 3)
        col_nam_2 = value_cols[1] # Middle (NƒÉm 2)
        col_nam_1 = value_cols[2] # Oldest (NƒÉm 1)
        
        # 3. X√≥a c√°c h√†ng ch·ªâ ch·ª©a d·ªØ li·ªáu ph·ª• (h√†ng ph·ª• c·ªßa Header g·ªëc)
        # H√†ng 0 trong df_raw (h√†ng th·ª© hai trong file g·ªëc) th∆∞·ªùng ch·ª©a c√°c gi√° tr·ªã NaN v√† ti√™u ƒë·ªÅ ph·ª• nh∆∞ "SS (+/-)"
        df_raw = df_raw.drop(df_raw.index[0])
        
        # 4. T·∫°o DataFrame m·ªõi ch·ªâ ch·ª©a 4 c·ªôt c·∫ßn thi·∫øt (Ch·ªâ ti√™u + 3 nƒÉm)
        df_final = df_raw[['Ch·ªâ ti√™u', col_nam_1, col_nam_2, col_nam_3]].copy()
        
        # 5. ƒê·ªïi t√™n c·ªôt ƒë·ªÉ ph√π h·ª£p v·ªõi h√†m process_financial_data
        df_final.columns = ['Ch·ªâ ti√™u', 'NƒÉm 1', 'NƒÉm 2', 'NƒÉm 3']
        
        # 6. L·ªçc b·ªè c√°c h√†ng NaN ·ªü c·ªôt 'Ch·ªâ ti√™u' (c√°c h√†ng tr·ªëng)
        df_final = df_final.dropna(subset=['Ch·ªâ ti√™u'])
        
        # X·ª≠ l√Ω d·ªØ li·ªáu
        df_processed = process_financial_data(df_final.copy())

        if df_processed is not None:
            
            # -----------------------------------------------------
            # S·ª¨A L·ªñI: L·ªåC B·ªé PH·∫¶N GI·ªú V√Ä CHUY·ªÇN SANG ƒê·ªäNH D·∫†NG DD/MM/YYYY
            # -----------------------------------------------------
            def format_col_name(col_name):
                col_name = str(col_name)
                # Lo·∫°i b·ªè ph·∫ßn gi·ªù n·∫øu c√≥
                if ' ' in col_name:
                    col_name = col_name.split(' ')[0]
                
                # Chuy·ªÉn t·ª´ YYYY-MM-DD sang DD/MM/YYYY
                try:
                    # T√°ch YYYY, MM, DD d·ª±a tr√™n d·∫•u '-'
                    parts = col_name.split('-')
                    if len(parts) == 3:
                        return f"{parts[2]}/{parts[1]}/{parts[0]}"
                except Exception:
                    # N·∫øu kh√¥ng ph·∫£i ƒë·ªãnh d·∫°ng YYYY-MM-DD (v√≠ d·ª•: ch·ªâ l√† '2023'), gi·ªØ nguy√™n
                    pass

                return col_name

            Y1_Name = format_col_name(col_nam_1)
            Y2_Name = format_col_name(col_nam_2)
            Y3_Name = format_col_name(col_nam_3)
            # -----------------------------------------------------
            
            # --- Ch·ª©c nƒÉng 2 & 3: Hi·ªÉn th·ªã K·∫øt qu·∫£ theo Tabs ---
            st.subheader("2. Ph√¢n t√≠ch T·ªëc ƒë·ªô TƒÉng tr∆∞·ªüng & 3. Ph√¢n t√≠ch T·ª∑ tr·ªçng C∆° c·∫•u T√†i s·∫£n")
            
            # 1. T·∫†O DATAFRAME TƒÇNG TR∆Ø·ªûNG (GH√âP C·ªòT)
            df_growth = df_processed[['Ch·ªâ ti√™u', 'NƒÉm 1', 'NƒÉm 2', 'NƒÉm 3', 
                                    'Delta (Y2 vs Y1)', 'Growth (Y2 vs Y1)', 
                                    'Delta (Y3 vs Y2)', 'Growth (Y3 vs Y2)']].copy()
            
            # ƒê·ªïi t√™n c·ªôt cho tr·ª±c quan (theo y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng)
            df_growth.columns = [
                'Ch·ªâ ti√™u', Y1_Name, Y2_Name, Y3_Name, 
                f'S.S Tuy·ªát ƒë·ªëi ({Y2_Name} vs {Y1_Name})', 
                f'S.S T∆∞∆°ng ƒë·ªëi (%) ({Y2_Name} vs {Y1_Name})',
                f'S.S Tuy·ªát ƒë·ªëi ({Y3_Name} vs {Y2_Name})', 
                f'S.S T∆∞∆°ng ƒë·ªëi (%) ({Y3_Name} vs {Y2_Name})'
            ]
            
            # 2. T·∫†O DATAFRAME C∆† C·∫§U
            df_structure = df_processed[['Ch·ªâ ti√™u', 'NƒÉm 1', 'NƒÉm 2', 'NƒÉm 3', 
                                         'T·ª∑ tr·ªçng NƒÉm 1 (%)', 'T·ª∑ tr·ªçng NƒÉm 2 (%)', 'T·ª∑ tr·ªçng NƒÉm 3 (%)']].copy()
            
            # ƒê·ªïi t√™n c·ªôt cho tr·ª±c quan
            df_structure.columns = [
                'Ch·ªâ ti√™u', Y1_Name, Y2_Name, Y3_Name, 
                f'T·ª∑ tr·ªçng {Y1_Name} (%)', f'T·ª∑ tr·ªçng {Y2_Name} (%)', f'T·ª∑ tr·ªçng {Y3_Name} (%)'
            ]

            tab1, tab2 = st.tabs(["üìà T·ªëc ƒë·ªô TƒÉng tr∆∞·ªüng (3 NƒÉm)", "üèóÔ∏è T·ª∑ tr·ªçng C∆° c·∫•u (3 NƒÉm)"])
            
            with tab1:
                st.markdown("##### B·∫£ng ph√¢n t√≠ch T·ªëc ƒë·ªô TƒÉng tr∆∞·ªüng & So s√°nh Tuy·ªát ƒë·ªëi (2 chu k·ª≥)")
                st.dataframe(df_growth.style.format({
                    Y1_Name: '{:,.0f}',
                    Y2_Name: '{:,.0f}',
                    Y3_Name: '{:,.0f}',
                    f'S.S Tuy·ªát ƒë·ªëi ({Y2_Name} vs {Y1_Name})': '{:,.0f}',
                    f'S.S Tuy·ªát ƒë·ªëi ({Y3_Name} vs {Y2_Name})': '{:,.0f}',
                    f'S.S T∆∞∆°ng ƒë·ªëi (%) ({Y2_Name} vs {Y1_Name})': '{:.2f}%',
                    f'S.S T∆∞∆°ng ƒë·ªëi (%) ({Y3_Name} vs {Y2_Name})': '{:.2f}%'
                }), use_container_width=True, hide_index=True)
                
            with tab2:
                st.markdown("##### B·∫£ng ph√¢n t√≠ch T·ª∑ tr·ªçng C∆° c·∫•u T√†i s·∫£n (%) (3 NƒÉm)")
                st.dataframe(df_structure.style.format({
                    Y1_Name: '{:,.0f}',
                    Y2_Name: '{:,.0f}',
                    Y3_Name: '{:,.0f}',
                    f'T·ª∑ tr·ªçng {Y1_Name} (%)': '{:.2f}%',
                    f'T·ª∑ tr·ªçng {Y2_Name} (%)': '{:.2f}%',
                    f'T·ª∑ tr·ªçng {Y3_Name} (%)': '{:.2f}%'
                }), use_container_width=True, hide_index=True)
            
            # Kh·ªüi t·∫°o gi√° tr·ªã m·∫∑c ƒë·ªãnh cho ch·ªâ s·ªë thanh to√°n
            thanh_toan_hien_hanh_N1 = "N/A"
            thanh_toan_hien_hanh_N2 = "N/A"
            thanh_toan_hien_hanh_N3 = "N/A"

            # --- Ch·ª©c nƒÉng 4: T√≠nh Ch·ªâ s·ªë T√†i ch√≠nh ---
            st.subheader("4. C√°c Ch·ªâ s·ªë T√†i ch√≠nh C∆° b·∫£n")
            
            try:
                # L·∫•y T√†i s·∫£n ng·∫Øn h·∫°n (TSNH)
                tsnh_n3 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm 3'].iloc[0]
                tsnh_n2 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm 2'].iloc[0]
                tsnh_n1 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm 1'].iloc[0]

                # L·∫•y N·ª£ ng·∫Øn h·∫°n (NNH)
                no_ngan_han_N3 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('N·ª¢ NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm 3'].iloc[0]  
                no_ngan_han_N2 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('N·ª¢ NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm 2'].iloc[0]
                no_ngan_han_N1 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('N·ª¢ NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm 1'].iloc[0]

                # T√≠nh to√°n
                thanh_toan_hien_hanh_N3 = tsnh_n3 / no_ngan_han_N3
                thanh_toan_hien_hanh_N2 = tsnh_n2 / no_ngan_han_N2
                thanh_toan_hien_hanh_N1 = tsnh_n1 / no_ngan_han_N1
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric(
                        label=f"Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh ({Y1_Name})",
                        value=f"{thanh_toan_hien_hanh_N1:.2f} l·∫ßn"
                    )
                with col2:
                    st.metric(
                        label=f"Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh ({Y2_Name})",
                        value=f"{thanh_toan_hien_hanh_N2:.2f} l·∫ßn",
                        delta=f"{thanh_toan_hien_hanh_N2 - thanh_toan_hien_hanh_N1:.2f}"
                    )
                with col3:
                    st.metric(
                        label=f"Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh ({Y3_Name})",
                        value=f"{thanh_toan_hien_hanh_N3:.2f} l·∫ßn",
                        delta=f"{thanh_toan_hien_hanh_N3 - thanh_toan_hien_hanh_N2:.2f}"
                    )
                    
            except IndexError:
                st.warning("Thi·∫øu ch·ªâ ti√™u 'T√ÄI S·∫¢N NG·∫ÆN H·∫†N' ho·∫∑c 'N·ª¢ NG·∫ÆN H·∫†N' ƒë·ªÉ t√≠nh ch·ªâ s·ªë.")
            except ZeroDivisionError:
                st.error("L·ªói chia cho 0 khi t√≠nh ch·ªâ s·ªë thanh to√°n. Vui l√≤ng ki·ªÉm tra d·ªØ li·ªáu 'N·ª£ Ng·∫Øn H·∫°n'!")
            
            # --- C·∫¨P NH·∫¨T D·ªÆ LI·ªÜU CHO CHATBOT (CONTEXT) ---
            data_for_chat_context = pd.DataFrame({
                'Ch·ªâ ti√™u': [
                    'To√†n b·ªô B·∫£ng ph√¢n t√≠ch (d·ªØ li·ªáu th√¥)', 
                    f'Thanh to√°n hi·ªán h√†nh ({Y1_Name})', 
                    f'Thanh to√°n hi·ªán h√†nh ({Y2_Name})',
                    f'Thanh to√°n hi·ªán h√†nh ({Y3_Name})'
                ],
                'Gi√° tr·ªã': [
                    df_processed.to_markdown(index=False),
                    f"{thanh_toan_hien_hanh_N1}", 
                    f"{thanh_toan_hien_hanh_N2}",
                    f"{thanh_toan_hien_hanh_N3}"
                ]
            }).to_markdown(index=False)
            st.session_state.data_for_chat = data_for_chat_context
            
            # C·∫≠p nh·∫≠t tin nh·∫Øn ch√†o m·ª´ng n·∫øu data ƒë√£ s·∫µn s√†ng
            if st.session_state.messages[0]["content"].startswith("Xin ch√†o!") or st.session_state.messages[0]["content"].startswith("Ph√¢n t√≠ch"):
                 st.session_state.messages[0]["content"] = f"Ph√¢n t√≠ch 3 k·ª≥ ({Y1_Name} ƒë·∫øn {Y3_Name}) ƒë√£ ho√†n t·∫•t! B√¢y gi·ªù b·∫°n c√≥ th·ªÉ h·ªèi t√¥i b·∫•t k·ª≥ ƒëi·ªÅu g√¨ v·ªÅ 'T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng', 'T·ª∑ tr·ªçng' v√† 'Ch·ªâ s·ªë thanh to√°n hi·ªán h√†nh' c·ªßa b√°o c√°o n√†y."

            # --- Ch·ª©c nƒÉng 5: Nh·∫≠n x√©t AI ---
            st.subheader("5. Nh·∫≠n x√©t T√¨nh h√¨nh T√†i ch√≠nh (AI)")
            
            # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ g·ª≠i cho AI (gi·ªëng h·ªát logic data_for_chat_context)
            try:
                tsnh_growth_y2y1 = f"{df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['Growth (Y2 vs Y1)'].iloc[0]:.2f}%"
                tsnh_growth_y3y2 = f"{df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['Growth (Y3 vs Y2)'].iloc[0]:.2f}%"
            except IndexError:
                tsnh_growth_y2y1 = "N/A"
                tsnh_growth_y3y2 = "N/A"

            data_for_ai = pd.DataFrame({
                'Ch·ªâ ti√™u': [
                    'To√†n b·ªô B·∫£ng ph√¢n t√≠ch (d·ªØ li·ªáu th√¥)', 
                    f'TƒÉng tr∆∞·ªüng T√†i s·∫£n ng·∫Øn h·∫°n ({Y2_Name} vs {Y1_Name})',
                    f'TƒÉng tr∆∞·ªüng T√†i s·∫£n ng·∫Øn h·∫°n ({Y3_Name} vs {Y2_Name})',
                    f'Thanh to√°n hi·ªán h√†nh ({Y1_Name})', 
                    f'Thanh to√°n hi·ªán h√†nh ({Y2_Name})',
                    f'Thanh to√°n hi·ªán h√†nh ({Y3_Name})'
                ],
                'Gi√° tr·ªã': [
                    df_processed.to_markdown(index=False),
                    tsnh_growth_y2y1,
                    tsnh_growth_y3y2,
                    f"{thanh_toan_hien_hanh_N1}", 
                    f"{thanh_toan_hien_hanh_N2}", 
                    f"{thanh_toan_hien_hanh_N3}"
                ]
            }).to_markdown(index=False)

            if st.button("Y√™u c·∫ßu AI Ph√¢n t√≠ch (Nh·∫≠n x√©t Chung)"):
                api_key = st.secrets.get("GEMINI_API_KEY") 
                
                if api_key:
                    with st.spinner('ƒêang g·ª≠i d·ªØ li·ªáu v√† ch·ªù Gemini ph√¢n t√≠ch...'):
                        ai_result = get_ai_analysis(data_for_ai, api_key)
                        st.markdown("**K·∫øt qu·∫£ Ph√¢n t√≠ch t·ª´ Gemini AI:**")
                        st.info(ai_result)
                else:
                    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API. Vui l√≤ng c·∫•u h√¨nh Kh√≥a 'GEMINI_API_KEY' trong Streamlit Secrets.")

    except ValueError as ve:
        st.error(f"L·ªói c·∫•u tr√∫c d·ªØ li·ªáu: {ve}")
        st.session_state.data_for_chat = None # Reset chat context
    except Exception as e:
        st.error(f"C√≥ l·ªói x·∫£y ra khi ƒë·ªçc ho·∫∑c x·ª≠ l√Ω file: {e}. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng file v√† ƒë·∫£m b·∫£o c√≥ ƒë·ªß 3 c·ªôt nƒÉm.")
        st.session_state.data_for_chat = None # Reset chat context

else:
    st.info("Vui l√≤ng t·∫£i l√™n file Excel ho·∫∑c CSV ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")
    st.session_state.data_for_chat = None # ƒê·∫£m b·∫£o context ƒë∆∞·ª£c reset khi ch∆∞a c√≥ file

# --- Ch·ª©c nƒÉng 6: Khung Chatbot t∆∞∆°ng t√°c ---
st.subheader("6. Tr√≤ chuy·ªán v√† H·ªèi ƒë√°p (Gemini AI)")
if st.session_state.data_for_chat is None:
    st.info("Vui l√≤ng t·∫£i l√™n v√† x·ª≠ l√Ω b√°o c√°o t√†i ch√≠nh tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu tr√≤ chuy·ªán v·ªõi AI.")
else:
    # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # X·ª≠ l√Ω input m·ªõi t·ª´ ng∆∞·ªùi d√πng
    if prompt := st.chat_input("H·ªèi AI v·ªÅ b√°o c√°o t√†i ch√≠nh n√†y..."):
        api_key = st.secrets.get("GEMINI_API_KEY")
        
        if not api_key:
            st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API. Vui l√≤ng c·∫•u h√¨nh Kh√≥a 'GEMINI_API_KEY' trong Streamlit Secrets.")
        else:
            # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # T·∫°o ph·∫£n h·ªìi t·ª´ AI
            with st.chat_message("assistant"):
                with st.spinner("ƒêang g·ª≠i c√¢u h·ªèi v√† ch·ªù Gemini tr·∫£ l·ªùi..."):
                    
                    # G·ªçi h√†m chat m·ªõi
                    full_response = get_chat_response(
                        prompt, 
                        st.session_state.messages, 
                        st.session_state.data_for_chat, 
                        api_key
                    )
                    
                    st.markdown(full_response)
            
            # Th√™m ph·∫£n h·ªìi c·ªßa AI v√†o l·ªãch s·ª≠
            st.session_state.messages.append({"role": "assistant", "content": full_response})
